{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = r\".\\data\\properties.csv\"\n",
    "df = pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postal_zone'] = df['zip_code'].astype(str).str[:2]\n",
    "columns_to_drop = [\"id\", \"zip_code\", \"locality\",\"latitude\",\"longitude\",\"construction_year\",\"nbr_frontages\", \"equipped_kitchen\", \"epc\",\"fl_double_glazing\", \"state_building\", \"fl_open_fire\"]\n",
    "df = df.drop(labels=columns_to_drop, axis=1)\n",
    "# df = df.dropna(subset=[\"terrace_sqm\", \"garden_sqm\",\"primary_energy_consumption_sqm\",\"total_area_sqm\"])\n",
    "\n",
    "df = df[df[\"price\"] <= 1200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = \"APARTMENT\"\n",
    "\n",
    "df.loc[df['property_type'] == condition, 'surface_land_sqm'] = df.loc[df['property_type'] == condition, 'total_area_sqm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"price\"]\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=50, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BluePrint Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pipeline in scikit-learn is a sequence of data processing steps that are chained together. These steps typically include data preprocessing, feature extraction, and model fitting. Each step in the pipeline is represented by a tuple containing a name (string) and an estimator (an object implementing the fit and transform methods).\n",
    "\n",
    "An important aspect of pipelines in scikit-learn is their ability to uniformly handle transformations across all columns of the dataset. However not all data has to be handled the same way. A way to get around that is by using ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines for numerical transformations\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('imputer', KNNImputer(n_neighbors=5)) # You can adjust n_neighbors as needed. These \n",
    "    #, ...\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines for categorical transformations\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder())\n",
    "    #, ...\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the numerical columns\n",
    "numerical_columns = X_train.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Find the categorical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ColumnTransformer empowers me to precisely specify the columns within the dataset where transformations should be applied. This capability eliminates the necessity for manual dataset subsetting on my part. \n",
    "ColumnTransformer has an almost similar setup as the Pipeline, however the tuple requires another argument, namely the list of columns you want to apply the transformations on.\n",
    "Another note is that a pipeline can be part of another Pipeline or a ColumnTransformer.\n",
    "Below you can see how I input the previously designed Pipelines inside the ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical and categorical pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    #(name, method or pipeline, list of columns)\n",
    "    ('numerical', numerical_pipeline, numerical_columns),\n",
    "    ('categorical', categorical_pipeline, categorical_columns)\n",
    "    #, ...\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final pipeline\n",
    "regression_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    #, ... could add something for feature selection\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Pipeline and the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .fit() method in scikit-learn is used to train the machine learning model on the provided training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'.\\model.pkl'\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(regression_pipeline, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using saved model to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening Pipeline from Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = r'.\\model.pkl'\n",
    "with open(path_to_file, 'rb') as f:\n",
    "    regression_model_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regression_model_pickle.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression_model_pickle.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the name of features after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_step = regression_model_pickle.named_steps['preprocessor']\n",
    "feature_names_after_preprocessing = preprocessing_step.get_feature_names_out()\n",
    "print(feature_names_after_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A?\n",
    "\n",
    "LinkedIn: https://www.linkedin.com/in/jens-dedeyne/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
